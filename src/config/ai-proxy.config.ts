/**
 * AI Proxy Configuration (Zod Schema)
 *
 * @description
 * Cloud Run í”„ë¡ì‹œ íƒ€ì„ì•„ì›ƒ ë° ì„¤ì • ì¤‘ì•™í™”
 * Zod ìŠ¤í‚¤ë§ˆë¡œ íƒ€ì… ì•ˆì „ì„± ë° ëŸ°íƒ€ì„ ê²€ì¦ ë³´ì¥
 *
 * @created 2026-01-26
 *
 * @note maxDuration vs Timeout ì°¨ì´ì 
 * - maxDuration: Next.js ë¹Œë“œ íƒ€ì„ ìƒìˆ˜ (ë¼ìš°íŠ¸ íŒŒì¼ì—ì„œ ì •ì  export)
 * - timeout: ëŸ°íƒ€ì„ì— ì‚¬ìš©ë˜ëŠ” ì‹¤ì œ íƒ€ì„ì•„ì›ƒ (ì´ configì—ì„œ ê´€ë¦¬)
 *
 * ê³µì‹ Limitsë¥¼ ë°˜ì˜í•´ ìš´ì˜:
 * - Legacy runtime: Hobby ê¸°ë³¸ 10ì´ˆ, ìµœëŒ€ 60ì´ˆ / Pro ê¸°ë³¸ 15ì´ˆ, ìµœëŒ€ 300ì´ˆ
 * - Fluid Compute: Hobby/Pro ê¸°ë³¸ 300ì´ˆ, Pro/Enterprise ìµœëŒ€ 800ì´ˆ
 * - Edge streaming: ìµœì´ˆ ì‘ë‹µì€ 25ì´ˆ ë‚´ ì‹œì‘ í•„ìš”, ìŠ¤íŠ¸ë¦¬ë° ì§€ì† 300ì´ˆ
 *
 * Vercel í‹°ì–´ ë³€ê²½ ì‹œ:
 * 1. VERCEL_TIER ë˜ëŠ” VERCEL_PLAN í™˜ê²½ë³€ìˆ˜ë¡œ í‹°ì–´ ë°˜ì˜
 * 2. AI_MAX_FUNCTION_DURATION_SECONDS ë¡œ ëŸ°íƒ€ì„ ì˜ˆì‚° ì¡°ì •
 * 3. ë¼ìš°íŠ¸ì˜ maxDurationì€ ë¹Œë“œ íƒ€ì„ ìƒìˆ˜ë¡œ ë¬¸ì„œí™”
 */

import { z } from 'zod';
import { logger } from '@/lib/logging';

// ============================================================================
// Zod Schemas
// ============================================================================

/**
 * Vercel í‹°ì–´ ìŠ¤í‚¤ë§ˆ
 */
const VercelTierSchema = z.enum(['free', 'pro']).default('free');

const TierMaxDurationSecondsSchema = z.number().int().min(1).max(800).default(60);

const FunctionTimeoutReserveSchema = z
  .number()
  .int()
  .min(200)
  .max(10_000)
  .default(1_500);

/**
 * íƒ€ì„ì•„ì›ƒ ì„¤ì • ìŠ¤í‚¤ë§ˆ
 */
const TimeoutConfigSchema = z.object({
  min: z.number().min(1000).max(60000),
  max: z.number().min(1000).max(60000),
  default: z.number().min(1000).max(60000),
});

/**
 * ì¿¼ë¦¬ ë¼ìš°íŒ… ì„¤ì • ìŠ¤í‚¤ë§ˆ
 * @description ë³µì¡ë„ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë°/Job Queue ë¼ìš°íŒ… ì„ê³„ê°’
 */
const QueryRoutingConfigSchema = z.object({
  /** ë³µì¡ë„ ì„ê³„ê°’: ì´ ì ìˆ˜ ì´ˆê³¼ì‹œ Job Queue ì‚¬ìš© (ê¸°ë³¸ê°’: 19) */
  complexityThreshold: z.number().min(1).max(100).default(19),
  /** Job Queue ê°•ì œ ì‚¬ìš© í‚¤ì›Œë“œ */
  forceJobQueueKeywords: z.array(z.string()).default([
    'ë³´ê³ ì„œ', 'ë¦¬í¬íŠ¸', 'ê·¼ë³¸ ì›ì¸', 'ì¥ì•  ë¶„ì„', 'ì „ì²´ ë¶„ì„',
  ]),
});

/**
 * ìŠ¤íŠ¸ë¦¬ë° ì¬ì‹œë„ ì„¤ì • ìŠ¤í‚¤ë§ˆ
 * @description P1: Exponential backoff ì¬ì‹œë„ ì„¤ì •
 */
const StreamRetryConfigSchema = z.object({
  /** ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ */
  maxRetries: z.number().min(0).max(5).default(3),
  /** ì´ˆê¸° ëŒ€ê¸° ì‹œê°„ (ms) */
  initialDelayMs: z.number().min(100).max(5000).default(1000),
  /** ë°±ì˜¤í”„ ë°°ìˆ˜ */
  backoffMultiplier: z.number().min(1).max(5).default(2),
  /** ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ms) */
  maxDelayMs: z.number().min(1000).max(30000).default(10000),
  /** ğŸ¯ P0: Jitter ë²”ìœ„ (0.0 ~ 1.0, Thundering herd ë°©ì§€) */
  jitterFactor: z.number().min(0).max(1).default(0.1),
  /** ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ íŒ¨í„´ */
  retryableErrors: z.array(z.string()).default([
    'timeout', 'ETIMEDOUT', 'ECONNRESET', 'fetch failed',
    'socket hang up', '504', '503', 'Stream error',
  ]),
});

/**
 * RAG ê²€ìƒ‰ ê°€ì¤‘ì¹˜ ì„¤ì • ìŠ¤í‚¤ë§ˆ
 * @description P2: RAG í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ ì™¸ë¶€í™”
 */
const RAGWeightsConfigSchema = z.object({
  /** ë²¡í„° ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (pgVector) */
  vector: z.number().min(0).max(1).default(0.5),
  /** ê·¸ë˜í”„ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (Knowledge Graph) */
  graph: z.number().min(0).max(1).default(0.3),
  /** ì›¹ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (Tavily) */
  web: z.number().min(0).max(1).default(0.2),
});

/**
 * Observability ì„¤ì • ìŠ¤í‚¤ë§ˆ
 * @description P1: Trace ID ì „íŒŒ ë° ë¡œê¹… ì„¤ì •
 */
const ObservabilityConfigSchema = z.object({
  /** Trace ID ì „íŒŒ í™œì„±í™” */
  enableTraceId: z.boolean().default(true),
  /** Trace ID í—¤ë” ì´ë¦„ */
  traceIdHeader: z.string().default('X-Trace-Id'),
  /** ìƒì„¸ ë¡œê¹… í™œì„±í™” (ê°œë°œ í™˜ê²½) */
  verboseLogging: z.boolean().default(false),
});

/**
 * ì¿¼ë¦¬ ë³µì¡ë„ ì¹´í…Œê³ ë¦¬ ê°€ì¤‘ì¹˜ ìŠ¤í‚¤ë§ˆ
 * @description P1: ë³µì¡ë„ ë¶„ì„ ê°€ì¤‘ì¹˜ ì™¸ë¶€í™”
 * @see src/lib/ai/utils/query-complexity.ts
 */
const ComplexityCategoryWeightsSchema = z.object({
  /** ë¶„ì„ ê´€ë ¨ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ */
  analysis: z.number().min(0).max(50).default(20),
  /** ì˜ˆì¸¡ ê´€ë ¨ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ */
  prediction: z.number().min(0).max(50).default(25),
  /** ì§‘ê³„ ê´€ë ¨ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ */
  aggregation: z.number().min(0).max(50).default(15),
  /** ì‹œê°„ ë²”ìœ„ ê´€ë ¨ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ */
  timeRange: z.number().min(0).max(50).default(15),
  /** ë‹¤ì¤‘ ì„œë²„ ê´€ë ¨ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ */
  multiServer: z.number().min(0).max(50).default(15),
  /** ë³´ê³ ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ */
  report: z.number().min(0).max(50).default(20),
  /** ì›ì¸ ë¶„ì„ ê´€ë ¨ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ */
  rootCause: z.number().min(0).max(50).default(30),
  /** RAG ê²€ìƒ‰ ê´€ë ¨ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ */
  ragSearch: z.number().min(0).max(50).default(25),
});

/**
 * AI Proxy ì„¤ì • ìŠ¤í‚¤ë§ˆ
 */
const AIProxyConfigSchema = z.object({
  /** Vercel í‹°ì–´ (build-time ê¸°ì¤€): free/pro ëª¨ë‘ ëŸ°íƒ€ì„ ì œí•œ ë°˜ì˜ */
  tier: VercelTierSchema,

  /** í‹°ì–´ë³„ maxDuration (ë¹Œë“œ íƒ€ì„ ì°¸ì¡°ìš©) */
  maxDuration: z.object({
    free: TierMaxDurationSecondsSchema,
    pro: TierMaxDurationSecondsSchema,
  }),

  /** ëŸ°íƒ€ì„ì—ì„œ ì‹¤ì œë¡œ ì ìš©í•  ìµœëŒ€ í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ (ms) */
  maxFunctionDurationMs: z.number().int().min(1_000).max(800_000),

  /** ëŸ°íƒ€ì„ ì•ˆì „ ë§ˆì§„ (ms) */
  functionTimeoutReserveMs: FunctionTimeoutReserveSchema,

  /** ì—”ë“œí¬ì¸íŠ¸ë³„ íƒ€ì„ì•„ì›ƒ ì„¤ì • */
  timeouts: z.object({
    supervisor: TimeoutConfigSchema,
    'incident-report': TimeoutConfigSchema,
    'intelligent-monitoring': TimeoutConfigSchema,
    'analyze-server': TimeoutConfigSchema,
  }),

  /** ìºì‹œ TTL ì„¤ì • (ì´ˆ) */
  cacheTTL: z.object({
    'supervisor-status': z.number().default(300),
    supervisor: z.number().default(1800),
    'incident-report': z.number().default(3600),
    'intelligent-monitoring': z.number().default(600),
  }),

  /** ì¿¼ë¦¬ ë¼ìš°íŒ… ì„¤ì • */
  queryRouting: QueryRoutingConfigSchema,

  /** ìŠ¤íŠ¸ë¦¬ë° ì¬ì‹œë„ ì„¤ì • */
  streamRetry: StreamRetryConfigSchema,

  /** RAG ê²€ìƒ‰ ê°€ì¤‘ì¹˜ */
  ragWeights: RAGWeightsConfigSchema,

  /** Observability ì„¤ì • */
  observability: ObservabilityConfigSchema,

  /** ë³µì¡ë„ ì¹´í…Œê³ ë¦¬ ê°€ì¤‘ì¹˜ */
  complexityWeights: ComplexityCategoryWeightsSchema,
});

// ============================================================================
// Types
// ============================================================================

export type VercelTier = z.infer<typeof VercelTierSchema>;
export type TimeoutConfig = z.infer<typeof TimeoutConfigSchema>;
export type AIProxyConfig = z.infer<typeof AIProxyConfigSchema>;
export type ProxyEndpoint = keyof AIProxyConfig['timeouts'];
export type CacheEndpoint = keyof AIProxyConfig['cacheTTL'];
export type QueryRoutingConfig = z.infer<typeof QueryRoutingConfigSchema>;
export type StreamRetryConfig = z.infer<typeof StreamRetryConfigSchema>;
export type RAGWeightsConfig = z.infer<typeof RAGWeightsConfigSchema>;
export type ObservabilityConfig = z.infer<typeof ObservabilityConfigSchema>;
export type ComplexityCategoryWeights = z.infer<typeof ComplexityCategoryWeightsSchema>;

// ============================================================================
// Tier-specific Timeout Presets
// ============================================================================

/**
 * Free tier íƒ€ì„ì•„ì›ƒ ê¸°ë³¸ê°’(í˜„ì¬ 60ì´ˆ ìƒí•œ ê¸°ì¤€ ë³´ìˆ˜ê°’)
 */
const FREE_TIER_TIMEOUTS = {
  supervisor: { min: 3000, max: 9000, default: 5000 },
  'incident-report': { min: 5000, max: 9000, default: 7000 },
  'intelligent-monitoring': { min: 3000, max: 9000, default: 5000 },
  'analyze-server': { min: 3000, max: 9000, default: 5000 },
} as const;

/**
 * Pro tier íƒ€ì„ì•„ì›ƒ (ë¹„ìš© ì•ˆì •ì„±ì„ ê³ ë ¤í•´ í•˜í–¥ ê¸°ë³¸ê°’ì—ì„œ ì‹œì‘)
 */
const PRO_TIER_TIMEOUTS = {
  supervisor: { min: 15000, max: 55000, default: 30000 },
  'incident-report': { min: 20000, max: 45000, default: 30000 },
  'intelligent-monitoring': { min: 10000, max: 30000, default: 15000 },
  'analyze-server': { min: 8000, max: 25000, default: 12000 },
} as const;

const RAG_WEIGHTS_DEFAULT_KEYS = {
  vector: 'AI_RAG_WEIGHT_VECTOR',
  graph: 'AI_RAG_WEIGHT_GRAPH',
  web: 'AI_RAG_WEIGHT_WEB',
} as const;

const COMPLEXITY_WEIGHTS_DEFAULT_KEYS = {
  analysis: 'AI_COMPLEXITY_WEIGHT_ANALYSIS',
  prediction: 'AI_COMPLEXITY_WEIGHT_PREDICTION',
  aggregation: 'AI_COMPLEXITY_WEIGHT_AGGREGATION',
  timeRange: 'AI_COMPLEXITY_WEIGHT_TIME_RANGE',
  multiServer: 'AI_COMPLEXITY_WEIGHT_MULTI_SERVER',
  report: 'AI_COMPLEXITY_WEIGHT_REPORT',
  rootCause: 'AI_COMPLEXITY_WEIGHT_ROOT_CAUSE',
  ragSearch: 'AI_COMPLEXITY_WEIGHT_RAG_SEARCH',
} as const;

const DEFAULT_MAX_DURATION_SECONDS: Record<VercelTier, number> = {
  free: 60,
  pro: 300,
};

const parseOptionalIntEnv = (key: string): number | null => {
  const raw = process.env[key];
  if (!raw) return null;
  const parsed = Number.parseInt(raw, 10);
  return Number.isNaN(parsed) ? null : parsed;
};

const parseOptionalDecimalEnv = (key: string): number | null => {
  const raw = process.env[key];
  if (!raw) return null;
  const parsed = Number.parseFloat(raw);
  return Number.isNaN(parsed) ? null : parsed;
};

const parseOptionalBooleanEnv = (key: string): boolean | null => {
  const raw = process.env[key]?.trim().toLowerCase();
  if (!raw) return null;
  if (raw === 'true') return true;
  if (raw === 'false') return false;
  return null;
};

const parseStringListEnv = (key: string): string[] | null => {
  const raw = process.env[key];
  if (!raw) return null;
  return raw
    .split(',')
    .map((value) => value.trim())
    .filter(Boolean);
};

const parseNumericWithDefault = <T extends number>(
  key: string,
  fallback: T,
  validate: (value: number) => boolean
): T => {
  const parsed = parseOptionalIntEnv(key);
  return parsed === null || !validate(parsed) ? fallback : (parsed as T);
};

const parseDecimalWithDefault = <T extends number>(
  key: string,
  fallback: T,
  validate: (value: number) => boolean
): T => {
  const parsed = parseOptionalDecimalEnv(key);
  return parsed === null || !validate(parsed) ? fallback : (parsed as T);
};

const parseTier = (rawTier?: string, rawPlan?: string): VercelTier => {
  const tier = rawTier?.toLowerCase();
  const plan = rawPlan?.toLowerCase();

  if (tier === 'free' || tier === 'hobby' || tier === 'pro') {
    return tier === 'pro' ? 'pro' : 'free';
  }

  if (plan === 'free' || plan === 'hobby') {
    return 'free';
  }

  if (plan === 'pro' || plan === 'enterprise' || plan === 'ent') {
    return 'pro';
  }

  return 'free';
};

const clampTimeoutEnv = (value: number, min = 1_000, max = 60_000): number => {
  return Math.max(min, Math.min(max, value));
};

// ============================================================================
// Config Loader
// ============================================================================

/**
 * í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ ë° ê²€ì¦
 */
function loadAIProxyConfig(): AIProxyConfig {
  const tier = parseTier(
    process.env.VERCEL_TIER?.trim(),
    process.env.VERCEL_PLAN?.trim()
  );
  const timeouts = tier === 'pro' ? PRO_TIER_TIMEOUTS : FREE_TIER_TIMEOUTS;
  const configuredMaxDurationSeconds = parseNumericWithDefault(
    'AI_MAX_FUNCTION_DURATION_SECONDS',
    DEFAULT_MAX_DURATION_SECONDS[tier],
    (value) => value >= 10 && value <= 800
  );
  const functionTimeoutReserveMs = parseNumericWithDefault(
    'AI_FUNCTION_TIMEOUT_RESERVE_MS',
    tier === 'pro' ? 2_000 : 1_500,
    (value) => value >= 200 && value <= 10_000
  );
  const forceJobQueueKeywords = parseStringListEnv('AI_FORCE_JOB_QUEUE_KEYWORDS');

  const rawConfig = {
    tier,
    maxDuration: {
      free: clampTimeoutEnv(configuredMaxDurationSeconds, 10, 300),
      pro: clampTimeoutEnv(configuredMaxDurationSeconds, 10, 800),
    },
    maxFunctionDurationMs: clampTimeoutEnv(
      configuredMaxDurationSeconds * 1_000,
      1_000,
      800_000
    ),
    functionTimeoutReserveMs,
    timeouts,
    cacheTTL: {
      'supervisor-status': 300,
      supervisor: 1800,
      'incident-report': 3600,
      'intelligent-monitoring': 600,
    },
    queryRouting: {
      complexityThreshold: parseNumericWithDefault(
        'AI_COMPLEXITY_THRESHOLD',
        19,
        (value) => value >= 1 && value <= 100
      ),
      forceJobQueueKeywords:
        forceJobQueueKeywords ?? [
          'ë³´ê³ ì„œ', 'ë¦¬í¬íŠ¸', 'ê·¼ë³¸ ì›ì¸', 'ì¥ì•  ë¶„ì„', 'ì „ì²´ ë¶„ì„',
        ],
    },
    streamRetry: {
      maxRetries: parseNumericWithDefault(
        'AI_STREAM_MAX_RETRIES',
        3,
        (value) => value >= 0 && value <= 5
      ),
      initialDelayMs: parseNumericWithDefault(
        'AI_STREAM_INITIAL_DELAY',
        1_000,
        (value) => value >= 100 && value <= 5_000
      ),
      backoffMultiplier: parseNumericWithDefault(
        'AI_STREAM_BACKOFF_MULTIPLIER',
        2,
        (value) => value >= 1 && value <= 5
      ),
      maxDelayMs: parseNumericWithDefault(
        'AI_STREAM_MAX_DELAY',
        10_000,
        (value) => value >= 1_000 && value <= 30_000
      ),
      jitterFactor: parseDecimalWithDefault(
        'AI_STREAM_JITTER_FACTOR',
        0.1,
        (value) => value >= 0 && value <= 1
      ),
      retryableErrors: [
        'timeout', 'ETIMEDOUT', 'ECONNRESET', 'fetch failed',
        'socket hang up', '504', '503', 'Stream error',
      ],
    },
    ragWeights: {
      vector: parseDecimalWithDefault(
        RAG_WEIGHTS_DEFAULT_KEYS.vector,
        0.5,
        (value) => value >= 0 && value <= 1
      ),
      graph: parseDecimalWithDefault(
        RAG_WEIGHTS_DEFAULT_KEYS.graph,
        0.3,
        (value) => value >= 0 && value <= 1
      ),
      web: parseDecimalWithDefault(
        RAG_WEIGHTS_DEFAULT_KEYS.web,
        0.2,
        (value) => value >= 0 && value <= 1
      ),
    },
    observability: {
      enableTraceId: parseOptionalBooleanEnv('AI_ENABLE_TRACE_ID') !== false,
      traceIdHeader: process.env.AI_TRACE_ID_HEADER || 'X-Trace-Id',
      verboseLogging: process.env.AI_VERBOSE_LOGGING === 'true',
    },
    complexityWeights: {
      analysis: parseNumericWithDefault(
        COMPLEXITY_WEIGHTS_DEFAULT_KEYS.analysis,
        20,
        (value) => value >= 0 && value <= 50
      ),
      prediction: parseNumericWithDefault(
        COMPLEXITY_WEIGHTS_DEFAULT_KEYS.prediction,
        25,
        (value) => value >= 0 && value <= 50
      ),
      aggregation: parseNumericWithDefault(
        COMPLEXITY_WEIGHTS_DEFAULT_KEYS.aggregation,
        15,
        (value) => value >= 0 && value <= 50
      ),
      timeRange: parseNumericWithDefault(
        COMPLEXITY_WEIGHTS_DEFAULT_KEYS.timeRange,
        15,
        (value) => value >= 0 && value <= 50
      ),
      multiServer: parseNumericWithDefault(
        COMPLEXITY_WEIGHTS_DEFAULT_KEYS.multiServer,
        15,
        (value) => value >= 0 && value <= 50
      ),
      report: parseNumericWithDefault(
        COMPLEXITY_WEIGHTS_DEFAULT_KEYS.report,
        20,
        (value) => value >= 0 && value <= 50
      ),
      rootCause: parseNumericWithDefault(
        COMPLEXITY_WEIGHTS_DEFAULT_KEYS.rootCause,
        30,
        (value) => value >= 0 && value <= 50
      ),
      ragSearch: parseNumericWithDefault(
        COMPLEXITY_WEIGHTS_DEFAULT_KEYS.ragSearch,
        25,
        (value) => value >= 0 && value <= 50
      ),
    },
  };

  const result = AIProxyConfigSchema.safeParse(rawConfig);

  if (!result.success) {
    logger.error('âŒ AI Proxy config validation failed:', result.error.issues);
    throw new Error(
      `Invalid AI Proxy configuration: ${result.error.issues.map((i) => i.message).join(', ')}`
    );
  }

  return result.data;
}

// ============================================================================
// Singleton Instance
// ============================================================================

let _config: AIProxyConfig | null = null;

/**
 * AI Proxy ì„¤ì • ê°€ì ¸ì˜¤ê¸° (ì‹±ê¸€í†¤)
 */
export function getAIProxyConfig(): AIProxyConfig {
  if (!_config) {
    _config = loadAIProxyConfig();
    logger.info(`ğŸ”§ AI Proxy config loaded (tier: ${_config.tier})`);
  }
  return _config;
}

/**
 * ì„¤ì • ì¬ë¡œë“œ (í…ŒìŠ¤íŠ¸ìš©)
 */
export function reloadAIProxyConfig(): AIProxyConfig {
  _config = null;
  return getAIProxyConfig();
}

// ============================================================================
// Convenience Getters
// ============================================================================

/**
 * í˜„ì¬ Vercel í‹°ì–´
 */
export function getVercelTier(): VercelTier {
  return getAIProxyConfig().tier;
}

/**
 * í˜„ì¬ í‹°ì–´ì˜ maxDuration ê°’ (ë¹Œë“œ íƒ€ì„ ì°¸ì¡°ìš©)
 * @note ì‹¤ì œ ë¼ìš°íŠ¸ íŒŒì¼ì—ì„œëŠ” ë¦¬í„°ëŸ´ ê°’ ì‚¬ìš© í•„ìš”
 */
export function getCurrentMaxDuration(): number {
  const config = getAIProxyConfig();
  return config.maxDuration[config.tier];
}

/**
 * ë¼ìš°íŠ¸ maxDuration(ì´ˆ)ì™€ ëŸ°íƒ€ì„ ì œí•œì„ í•¨ê»˜ ê³ ë ¤í•œ ì‹¤í–‰ ìƒí•œ(ms)
 *
 * - routeMaxDurationSeconds: Next.js route.tsì—ì„œ export const maxDurationë¡œ ì„ ì–¸ëœ ê°’
 * - ëŸ°íƒ€ì„ ì œí•œ: AI_MAX_FUNCTION_DURATION_SECONDS ë˜ëŠ” ê¸°ë³¸ê°’
 *
 * ì–‘ìª½ ì¤‘ ë” ì‘ì€ ê°’ì„ ë°˜í™˜í•´ route-level ì„¤ì • ë³€ê²½ ì‹œ ê³¼í•œ íƒ€ì„ì•„ì›ƒì„ ë°©ì§€.
 */
export function getRouteMaxExecutionMs(routeMaxDurationSeconds: number): number {
  if (!Number.isFinite(routeMaxDurationSeconds) || routeMaxDurationSeconds <= 0) {
    return 0;
  }
  const routeMaxMs = routeMaxDurationSeconds * 1_000;
  return Math.max(0, Math.min(routeMaxMs, getMaxFunctionDurationMs()));
}

/**
 * í˜„ì¬ Vercel ëŸ°íƒ€ì„ ìµœëŒ€ ì‹¤í–‰ ì‹œê°„ (ms)
 */
export function getMaxFunctionDurationMs(): number {
  return getAIProxyConfig().maxFunctionDurationMs;
}

/**
 * í•¨ìˆ˜ ì¢…ë£Œ ì—¬ìœ  ë²„í¼ (ì‘ë‹µ ì²˜ë¦¬/ë¡œê¹…/ì§ë ¬í™” ì—¬ìœ )
 */
export function getFunctionTimeoutReserveMs(): number {
  return getAIProxyConfig().functionTimeoutReserveMs;
}

/**
 * ì—”ë“œí¬ì¸íŠ¸ë³„ ê¸°ë³¸ íƒ€ì„ì•„ì›ƒ
 */
export function getDefaultTimeout(endpoint: ProxyEndpoint): number {
  return getAIProxyConfig().timeouts[endpoint].default;
}

/**
 * ì—”ë“œí¬ì¸íŠ¸ë³„ ìµœëŒ€ íƒ€ì„ì•„ì›ƒ
 */
export function getMaxTimeout(endpoint: ProxyEndpoint): number {
  return getAIProxyConfig().timeouts[endpoint].max;
}

/**
 * ì—”ë“œí¬ì¸íŠ¸ë³„ ìµœì†Œ íƒ€ì„ì•„ì›ƒ
 */
export function getMinTimeout(endpoint: ProxyEndpoint): number {
  return getAIProxyConfig().timeouts[endpoint].min;
}

/**
 * íƒ€ì„ì•„ì›ƒ ê°’ì„ ìœ íš¨ ë²”ìœ„ë¡œ í´ë¨í”„
 */
export function clampTimeout(endpoint: ProxyEndpoint, timeout: number): number {
  const config = getAIProxyConfig().timeouts[endpoint];
  return Math.max(config.min, Math.min(config.max, timeout));
}

/**
 * ìºì‹œ TTL ê°€ì ¸ì˜¤ê¸° (ì´ˆ)
 */
export function getCacheTTL(endpoint: CacheEndpoint): number {
  return getAIProxyConfig().cacheTTL[endpoint];
}

// ============================================================================
// Query Routing Getters
// ============================================================================

/**
 * ë³µì¡ë„ ì„ê³„ê°’ ê°€ì ¸ì˜¤ê¸°
 * @description ì´ ì ìˆ˜ ì´ˆê³¼ì‹œ Job Queue ì‚¬ìš©
 */
export function getComplexityThreshold(): number {
  return getAIProxyConfig().queryRouting.complexityThreshold;
}

/**
 * Job Queue ê°•ì œ ì‚¬ìš© í‚¤ì›Œë“œ ëª©ë¡
 */
export function getForceJobQueueKeywords(): string[] {
  return getAIProxyConfig().queryRouting.forceJobQueueKeywords;
}

// ============================================================================
// Stream Retry Getters
// ============================================================================

/**
 * ìŠ¤íŠ¸ë¦¬ë° ì¬ì‹œë„ ì„¤ì • ì „ì²´ ê°€ì ¸ì˜¤ê¸°
 */
export function getStreamRetryConfig(): StreamRetryConfig {
  return getAIProxyConfig().streamRetry;
}

/**
 * ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ì¸ì§€ í™•ì¸
 */
export function isRetryableError(errorMessage: string): boolean {
  const config = getStreamRetryConfig();
  return config.retryableErrors.some(pattern =>
    errorMessage.toLowerCase().includes(pattern.toLowerCase())
  );
}

/**
 * ì¬ì‹œë„ ëŒ€ê¸° ì‹œê°„ ê³„ì‚° (ì§€ìˆ˜ ë°±ì˜¤í”„ + Jitter)
 *
 * @description
 * Thundering herd ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ Â±jitterFactor% ëœë¤ ì§€í„° ì¶”ê°€
 * ì˜ˆ: jitterFactor=0.1ì´ë©´ Â±10% ë²”ìœ„ì˜ ëœë¤ ë³€ë™
 *
 * @param attempt - í˜„ì¬ ì‹œë„ íšŸìˆ˜ (0ë¶€í„° ì‹œì‘)
 * @returns ì§€í„°ê°€ ì ìš©ëœ ëŒ€ê¸° ì‹œê°„ (ms)
 */
export function calculateRetryDelay(attempt: number): number {
  const config = getStreamRetryConfig();
  const baseDelay =
    config.initialDelayMs * Math.pow(config.backoffMultiplier, attempt);
  const cappedDelay = Math.min(baseDelay, config.maxDelayMs);

  // ğŸ¯ P0: Jitter ì ìš© (Â±jitterFactor% ë²”ìœ„)
  // Math.random()ì€ [0, 1) ë²”ìœ„ì´ë¯€ë¡œ (Math.random() * 2 - 1)ì€ [-1, 1) ë²”ìœ„
  const jitter = cappedDelay * config.jitterFactor * (Math.random() * 2 - 1);

  // ìµœì†Œ 100ms ë³´ì¥ (ìŒìˆ˜ ë°©ì§€)
  return Math.max(100, Math.round(cappedDelay + jitter));
}

// ============================================================================
// RAG Weights Getters
// ============================================================================

/**
 * RAG ê²€ìƒ‰ ê°€ì¤‘ì¹˜ ì „ì²´ ê°€ì ¸ì˜¤ê¸°
 */
export function getRAGWeights(): RAGWeightsConfig {
  return getAIProxyConfig().ragWeights;
}

// ============================================================================
// Observability Getters
// ============================================================================

/**
 * Observability ì„¤ì • ì „ì²´ ê°€ì ¸ì˜¤ê¸°
 */
export function getObservabilityConfig(): ObservabilityConfig {
  return getAIProxyConfig().observability;
}

// ============================================================================
// Complexity Weights Getters
// ============================================================================

/**
 * ë³µì¡ë„ ì¹´í…Œê³ ë¦¬ ê°€ì¤‘ì¹˜ ì „ì²´ ê°€ì ¸ì˜¤ê¸°
 * @description P1: query-complexity.tsì—ì„œ ì‚¬ìš©
 */
export function getComplexityCategoryWeights(): ComplexityCategoryWeights {
  return getAIProxyConfig().complexityWeights;
}

/**
 * íŠ¹ì • ì¹´í…Œê³ ë¦¬ ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸°
 */
export function getComplexityCategoryWeight(
  category: keyof ComplexityCategoryWeights
): number {
  return getAIProxyConfig().complexityWeights[category];
}

// ============================================================================
// W3C Trace Context (re-exported from ai-proxy/tracing.ts)
// ============================================================================
export {
  generateTraceId,
  generateTraceparent,
  parseTraceparentTraceId,
  TRACEPARENT_HEADER,
  traceIdToUUID,
} from './ai-proxy/tracing';

/**
 * ì‹œê³„ì—´ ë©”íŠ¸ë¦­ ë°ì´í„° Hook
 *
 * íŠ¹ì • ì„œë²„ì˜ ì‹œê³„ì—´ ë©”íŠ¸ë¦­ ë°ì´í„°, ì˜ˆì¸¡, ì´ìƒíƒì§€ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
 */

'use client';

import { useCallback, useEffect, useState } from 'react';
import { z } from 'zod';
import { logger } from '@/lib/logging';

// ============================================================================
// Types
// ============================================================================

export interface MetricDataPoint {
  timestamp: string;
  value: number;
}

export interface PredictionDataPoint {
  timestamp: string;
  predicted: number;
  upper: number;
  lower: number;
}

export interface AnomalyDataPoint {
  startTime: string;
  endTime: string;
  severity: 'low' | 'medium' | 'high' | 'critical';
  metric: string;
  description: string;
}

export interface TimeSeriesData {
  serverId: string;
  serverName: string;
  metric: string;
  history: MetricDataPoint[];
  prediction?: PredictionDataPoint[];
  anomalies?: AnomalyDataPoint[];
}

export interface UseTimeSeriesMetricsOptions {
  serverId: string;
  metric: 'cpu' | 'memory' | 'disk' | 'network';
  range?: '1h' | '6h' | '24h' | '7d';
  includePrediction?: boolean;
  includeAnomalies?: boolean;
  refreshInterval?: number; // ms, 0 = no auto refresh
}

export interface UseTimeSeriesMetricsResult {
  data: TimeSeriesData | null;
  isLoading: boolean;
  error: string | null;
  refetch: () => Promise<void>;
}

const rangeToServerRange: Record<
  NonNullable<UseTimeSeriesMetricsOptions['range']>,
  string
> = {
  '1h': '1h',
  '6h': '6h',
  '24h': '24h',
  '7d': '168h',
};

const legacyTimeSeriesResponseSchema = z.object({
  success: z.boolean(),
  data: z
    .object({
      serverId: z.string(),
      serverName: z.string(),
      metric: z.string(),
      history: z.array(
        z.object({
          timestamp: z.string(),
          value: z.number(),
        })
      ),
      prediction: z
        .array(
          z.object({
            timestamp: z.string(),
            predicted: z.number(),
            upper: z.number(),
            lower: z.number(),
          })
        )
        .optional(),
      anomalies: z
        .array(
          z.object({
            startTime: z.string(),
            endTime: z.string(),
            severity: z.enum(['low', 'medium', 'high', 'critical']),
            metric: z.string(),
            description: z.string(),
          })
        )
        .optional(),
    })
    .optional(),
  message: z.string().optional(),
});

const serverHistoryResponseSchema = z.object({
  success: z.boolean(),
  data: z
    .object({
      server_info: z
        .object({
          id: z.string().optional(),
          hostname: z.string().optional(),
        })
        .optional(),
      history: z
        .object({
          data_points: z
            .array(
              z.object({
                timestamp: z.string(),
                metrics: z
                  .object({
                    cpu_usage: z.number().optional(),
                    memory_usage: z.number().optional(),
                    disk_usage: z.number().optional(),
                    network_in: z.number().optional(),
                    network_out: z.number().optional(),
                  })
                  .passthrough(),
              })
            )
            .optional(),
        })
        .optional(),
      alerts: z
        .array(
          z.object({
            metric: z.string().optional(),
            severity: z.string().optional(),
            message: z.string().optional(),
            firedAt: z.string().optional(),
            resolvedAt: z.string().optional(),
          })
        )
        .optional(),
    })
    .optional(),
  message: z.string().optional(),
});

function mapMetricValue(
  metric: UseTimeSeriesMetricsOptions['metric'],
  metrics: {
    cpu_usage?: number;
    memory_usage?: number;
    disk_usage?: number;
    network_in?: number;
    network_out?: number;
  }
): number {
  switch (metric) {
    case 'cpu':
      return metrics.cpu_usage ?? 0;
    case 'memory':
      return metrics.memory_usage ?? 0;
    case 'disk':
      return metrics.disk_usage ?? 0;
    case 'network': {
      const inValue = metrics.network_in ?? 0;
      const outValue = metrics.network_out ?? 0;
      return Math.min(100, Math.max(0, inValue + outValue));
    }
    default:
      return 0;
  }
}

function normalizeAlertSeverity(value?: string): AnomalyDataPoint['severity'] {
  switch (value) {
    case 'critical':
      return 'critical';
    case 'high':
      return 'high';
    case 'warning':
    case 'medium':
      return 'medium';
    default:
      return 'low';
  }
}

function normalizeToTimeSeriesData(
  payload: unknown,
  options: {
    serverId: string;
    metric: UseTimeSeriesMetricsOptions['metric'];
    includePrediction: boolean;
    includeAnomalies: boolean;
  }
): TimeSeriesData {
  const legacyParsed = legacyTimeSeriesResponseSchema.safeParse(payload);
  if (
    legacyParsed.success &&
    legacyParsed.data.success &&
    legacyParsed.data.data
  ) {
    return {
      ...legacyParsed.data.data,
      prediction: options.includePrediction
        ? legacyParsed.data.data.prediction
        : undefined,
    };
  }

  const serverParsed = serverHistoryResponseSchema.safeParse(payload);
  if (
    serverParsed.success &&
    serverParsed.data.success &&
    serverParsed.data.data
  ) {
    const serverData = serverParsed.data.data;
    const historyPoints = serverData.history?.data_points ?? [];
    const history = historyPoints.map((point) => ({
      timestamp: point.timestamp,
      value: mapMetricValue(options.metric, point.metrics),
    }));

    const anomalies = options.includeAnomalies
      ? (serverData.alerts ?? []).map((alert) => {
          const startTime = alert.firedAt ?? new Date().toISOString();
          const endTime = alert.resolvedAt ?? startTime;
          return {
            startTime,
            endTime,
            severity: normalizeAlertSeverity(alert.severity),
            metric: alert.metric ?? options.metric,
            description:
              alert.message ?? `${options.metric.toUpperCase()} ì´ìƒì¹˜ ê°ì§€`,
          };
        })
      : undefined;

    return {
      serverId: serverData.server_info?.id ?? options.serverId,
      serverName: serverData.server_info?.hostname ?? options.serverId,
      metric: options.metric,
      history,
      anomalies,
    };
  }

  throw new Error('ì‹œê³„ì—´ API ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.');
}

// ============================================================================
// Hook
// ============================================================================

export function useTimeSeriesMetrics({
  serverId,
  metric,
  range = '6h',
  includePrediction = true,
  includeAnomalies = true,
  refreshInterval = 0,
}: UseTimeSeriesMetricsOptions): UseTimeSeriesMetricsResult {
  const [data, setData] = useState<TimeSeriesData | null>(null);
  const [isLoading, setIsLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);

  // ğŸ”§ AbortControllerë¥¼ ì‚¬ìš©í•œ ì•ˆì „í•œ fetch
  const fetchData = useCallback(
    async (signal?: AbortSignal) => {
      if (!serverId || !metric) {
        setData(null);
        setIsLoading(false);
        return;
      }

      setIsLoading(true);
      setError(null);

      try {
        const params = new URLSearchParams({
          history: 'true',
          range: rangeToServerRange[range],
          format: 'enhanced',
          include_metrics: 'true',
        });

        const response = await fetch(
          `/api/servers/${encodeURIComponent(serverId)}?${params.toString()}`,
          {
            signal, // ğŸ”§ AbortController signal ì „ë‹¬
          }
        );

        if (!response.ok) {
          // 404ëŠ” ë°ì´í„° ì—†ìŒ - ì—ëŸ¬ë¡œ ì·¨ê¸‰í•˜ì§€ ì•ŠìŒ (Graceful Degradation)
          if (response.status === 404) {
            setData(null);
            setIsLoading(false);
            return;
          }
          throw new Error(`API ì˜¤ë¥˜: ${response.status}`);
        }

        const result = await response.json();

        if (!result.success) {
          throw new Error(result.message || 'ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨');
        }

        setData(
          normalizeToTimeSeriesData(result, {
            serverId,
            metric,
            includePrediction,
            includeAnomalies,
          })
        );
      } catch (err) {
        // ğŸ”§ AbortErrorëŠ” ì •ìƒì ì¸ cleanupì´ë¯€ë¡œ ë¬´ì‹œ
        if (err instanceof Error && err.name === 'AbortError') {
          return;
        }
        // ì˜ˆìƒ ê°€ëŠ¥í•œ ì—ëŸ¬ëŠ” debugë¡œ ì²˜ë¦¬
        const message = err instanceof Error ? err.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
        if (message.includes('404')) {
          logger.debug('ì‹œê³„ì—´ ë°ì´í„° ì—†ìŒ:', message);
        } else {
          logger.warn('ì‹œê³„ì—´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨:', err);
        }
        setError(message);
      } finally {
        setIsLoading(false);
      }
    },
    [serverId, metric, range, includePrediction, includeAnomalies]
  );

  // ğŸ”§ Initial fetch with AbortController
  useEffect(() => {
    const abortController = new AbortController();
    void fetchData(abortController.signal);

    return () => {
      abortController.abort(); // ì»´í¬ë„ŒíŠ¸ unmount ì‹œ fetch ì·¨ì†Œ
    };
  }, [fetchData]);

  // ğŸ”§ Auto refresh with AbortController
  useEffect(() => {
    if (refreshInterval <= 0) return;

    let abortController: AbortController | null = null;

    const interval = setInterval(() => {
      abortController = new AbortController();
      void fetchData(abortController.signal);
    }, refreshInterval);

    return () => {
      clearInterval(interval);
      abortController?.abort(); // ì§„í–‰ ì¤‘ì¸ fetch ì·¨ì†Œ
    };
  }, [fetchData, refreshInterval]);

  return {
    data,
    isLoading,
    error,
    refetch: fetchData,
  };
}

export default useTimeSeriesMetrics;

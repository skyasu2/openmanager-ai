/**
 * useHybridAIQuery Hook
 *
 * @description ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¼ ìë™ìœ¼ë¡œ ìµœì ì˜ ë°©ì‹ì„ ì„ íƒí•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ AI ì¿¼ë¦¬ í›…
 *
 * ë¼ìš°íŒ… ì „ëµ:
 * - simple (score â‰¤ 20): useChat (ë¹ ë¥¸ ìŠ¤íŠ¸ë¦¬ë°)
 * - moderate (20 < score â‰¤ 45): useChat (í‘œì¤€ ìŠ¤íŠ¸ë¦¬ë°)
 * - complex/very_complex (score > 45): Job Queue (ì§„í–‰ë¥  í‘œì‹œ + íƒ€ì„ì•„ì›ƒ íšŒí”¼)
 *
 * Architecture (split into sub-hooks):
 * - core/useQueryExecution.ts: executeQuery + sendQuery routing
 * - core/useQueryControls.ts: stop, cancel, reset, previewComplexity
 * - core/useClarificationHandlers.ts: clarification flow
 *
 * @example
 * ```tsx
 * const { sendQuery, messages, isLoading, progress, mode } = useHybridAIQuery({
 *   sessionId: 'session_123',
 * });
 *
 * const handleSubmit = () => {
 *   sendQuery(userInput);
 * };
 * ```
 *
 * @created 2025-12-30
 * @updated 2026-02-10 - Split into sub-hooks (876 â†’ ~590 lines)
 */

import type { UIMessage } from '@ai-sdk/react';
import { useChat } from '@ai-sdk/react';
import { DefaultChatTransport } from 'ai';
import { useEffect, useMemo, useRef, useState } from 'react';
import {
  calculateRetryDelay,
  generateTraceId,
  generateTraceparent,
  getComplexityThreshold,
  getObservabilityConfig,
  getStreamRetryConfig,
  isRetryableError,
  TRACEPARENT_HEADER,
} from '@/config/ai-proxy.config';
import { extractStreamError } from '@/lib/ai/constants/stream-errors';
import { logger } from '@/lib/logging';
import { useClarificationHandlers } from './core/useClarificationHandlers';
import { useQueryControls } from './core/useQueryControls';
import { useQueryExecution } from './core/useQueryExecution';
import { useAsyncAIQuery } from './useAsyncAIQuery';
import { generateMessageId } from './utils/hybrid-query-utils';

// ============================================================================
// Types (extracted to types/hybrid-query.types.ts)
// ============================================================================
export type {
  AgentStatus,
  AgentStatusEventData,
  ClarificationOption,
  ClarificationRequest,
  HandoffEventData,
  HybridQueryState,
  QueryMode,
  RedirectEventData,
  StreamDataPart,
  StreamEventType,
  UseHybridAIQueryOptions,
  UseHybridAIQueryReturn,
  WarningEventData,
} from './types/hybrid-query.types';

// ============================================================================
// Error Detection Constants (SSOT)
// ============================================================================
import {
  COLD_START_ERROR_PATTERNS,
  isColdStartRelatedError,
  STREAM_ERROR_MARKER,
  STREAM_ERROR_REGEX,
} from '@/lib/ai/constants/stream-errors';
import type {
  HybridQueryState,
  RedirectEventData,
  StreamDataPart,
  UseHybridAIQueryOptions,
  UseHybridAIQueryReturn,
  WarningEventData,
} from './types/hybrid-query.types';
import type { FileAttachment } from './useFileAttachments';

// Re-export for consumers
export {
  STREAM_ERROR_MARKER,
  COLD_START_ERROR_PATTERNS,
  STREAM_ERROR_REGEX,
  extractStreamError,
  isColdStartRelatedError,
};

// ============================================================================
// Constants (moved to config/ai-proxy.config.ts)
// ============================================================================
// Note: DEFAULT_COMPLEXITY_THRESHOLD has been moved to ai-proxy.config.ts
// Use getComplexityThreshold() to access the configurable value

// ============================================================================
// Hook Implementation
// ============================================================================

export function useHybridAIQuery(
  options: UseHybridAIQueryOptions = {}
): UseHybridAIQueryReturn {
  const {
    sessionId: initialSessionId,
    apiEndpoint: customEndpoint,
    complexityThreshold = getComplexityThreshold(),
    onStreamFinish,
    onJobResult,
    onProgress,
    onData,
    webSearchEnabled,
  } = options;

  // ğŸ¯ P1: Trace ID for observability
  const traceIdRef = useRef<string>(generateTraceId());
  const observabilityConfig = getObservabilityConfig();

  // ğŸ¯ P1: Stream retry state
  const retryCountRef = useRef<number>(0);
  const streamRetryConfig = getStreamRetryConfig();

  // webSearchEnabledë¥¼ refë¡œ ì¶”ì : DefaultChatTransportì˜ bodyëŠ” ChatStore ìƒì„± ì‹œ
  // readonlyë¡œ ê³ ì •ë˜ë¯€ë¡œ, Resolvable<object> í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ í˜¸ì¶œ ì‹œì ì˜ ìµœì‹  ê°’ì„ ë°˜í™˜
  const webSearchEnabledRef = useRef(webSearchEnabled ?? false);
  useEffect(() => {
    webSearchEnabledRef.current = webSearchEnabled ?? false;
  }, [webSearchEnabled]);

  // Determine API endpoint (v2 only - v1 deprecated and removed)
  const apiEndpoint = customEndpoint ?? '/api/ai/supervisor/stream/v2';

  // Session ID with stable initial value
  const sessionIdRef = useRef<string>(
    initialSessionId || generateMessageId('session')
  );

  // State
  const [resumeEnabled, setResumeEnabled] = useState(true);
  const [state, setState] = useState<HybridQueryState>({
    mode: 'streaming',
    complexity: null,
    progress: null,
    jobId: null,
    isLoading: false,
    error: null,
    clarification: null,
    warning: null,
    processingTime: 0,
  });

  // ëª…í™•í™” ê±´ë„ˆë›°ê¸° ì‹œ ì›ë³¸ ì¿¼ë¦¬ ì €ì¥
  const pendingQueryRef = useRef<string | null>(null);
  // íŒŒì¼ ì²¨ë¶€ ì €ì¥ (ëª…í™•í™” í”Œë¡œìš°ì—ì„œ ì‚¬ìš©)
  const pendingAttachmentsRef = useRef<FileAttachment[] | null>(null);
  // Redirect ì´ë²¤íŠ¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì¿¼ë¦¬ ì €ì¥
  const currentQueryRef = useRef<string | null>(null);
  // ğŸ”’ Error Race Condition ë°©ì§€
  const errorHandledRef = useRef<boolean>(false);
  // AbortController for graceful request cancellation
  const abortControllerRef = useRef<AbortController | null>(null);
  // Retry setTimeout ID for cleanup on unmount
  const retryTimeoutRef = useRef<ReturnType<typeof setTimeout> | null>(null);

  // ============================================================================
  // useChat Hook (Streaming Mode) - AI SDK v6
  // ============================================================================
  const transport = useMemo(
    () =>
      new DefaultChatTransport({
        api: apiEndpoint,
        headers: () => ({
          [TRACEPARENT_HEADER]: generateTraceparent(traceIdRef.current),
          [observabilityConfig.traceIdHeader]: traceIdRef.current,
        }),
        body: () => ({ enableWebSearch: webSearchEnabledRef.current }),
        prepareReconnectToStreamRequest: ({ id }) => ({
          api: `${apiEndpoint}?sessionId=${id}`,
        }),
      }),
    [apiEndpoint, observabilityConfig.traceIdHeader]
  );

  const {
    messages,
    sendMessage,
    status: chatStatus,
    setMessages,
    stop: stopChat,
  } = useChat({
    id: sessionIdRef.current,
    transport,
    // Abort/stop ì‚¬ìš© í›„ì—ëŠ” í˜„ì¬ ìŠ¤íŠ¸ë¦¼ ì¬ì—°ê²°ì„ ë¹„í™œì„±í™”í•˜ê³ ,
    // ìƒˆ ì¿¼ë¦¬ ì‹œì‘ ì‹œì—ë§Œ ë‹¤ì‹œ í™œì„±í™”í•´ resume+abort ì¶©ëŒ ê°€ëŠ¥ì„±ì„ ì¤„ì¸ë‹¤.
    resume: resumeEnabled,
    onFinish: ({ message }) => {
      // ğŸ”’ Race Condition ë°©ì§€: onErrorê°€ ì´ë¯¸ ì—ëŸ¬ë¥¼ ì²˜ë¦¬í–ˆìœ¼ë©´ ìŠ¤í‚µ
      if (errorHandledRef.current) {
        logger.debug(
          '[HybridAI] onFinish skipped (error already handled by onError)'
        );
        setState((prev) => ({ ...prev, isLoading: false }));
        onStreamFinish?.();
        return;
      }

      // ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ í›„ ì—ëŸ¬ íŒ¨í„´ ê°ì§€
      const parts = message.parts ?? [];
      const content = parts
        .filter(
          (p): p is { type: 'text'; text: string } =>
            p != null && p.type === 'text'
        )
        .map((p) => p.text)
        .join('');

      const streamError = extractStreamError(content);

      if (streamError) {
        logger.warn(
          `[HybridAI] Stream error detected (trace: ${traceIdRef.current}): ${streamError}`
        );
        errorHandledRef.current = true;
        setState((prev) => ({
          ...prev,
          isLoading: false,
          error: streamError,
        }));
      } else {
        retryCountRef.current = 0;
        if (observabilityConfig.verboseLogging) {
          logger.info(
            `[HybridAI] Stream completed successfully (trace: ${traceIdRef.current})`
          );
        }
        setState((prev) => ({ ...prev, isLoading: false }));
      }
      onStreamFinish?.();
    },
    onData: (dataPart) => {
      const part = dataPart as StreamDataPart;

      // Warning ì´ë²¤íŠ¸ ì²˜ë¦¬
      if (part.type === 'data-warning' && part.data) {
        const warningData = part.data as WarningEventData;

        if (warningData.code === 'SLOW_PROCESSING') {
          logger.warn(
            `âš ï¸ [HybridAI] Slow processing: ${warningData.message} (${warningData.elapsed}ms)`
          );
          setState((prev) => {
            if (prev.warning) return prev;
            return {
              ...prev,
              warning: warningData.message,
              processingTime: warningData.elapsed,
            };
          });
        } else {
          logger.warn(`âš ï¸ [HybridAI] Stream error: ${warningData.message}`);
          setState((prev) => {
            if (prev.warning) return prev;
            return {
              ...prev,
              warning: warningData.message,
            };
          });
        }
        return;
      }

      // Redirect ì´ë²¤íŠ¸ ë‚´ë¶€ ì²˜ë¦¬ (Job Queue ëª¨ë“œ ì „í™˜)
      if (part.type === 'data-redirect' && part.data) {
        const redirectData = part.data as RedirectEventData;
        logger.info(
          `ğŸ”€ [HybridAI] Redirect received: switching to job-queue (${redirectData.complexity})`
        );

        setState((prev) => ({
          ...prev,
          mode: 'job-queue',
          complexity: redirectData.complexity,
          isLoading: true,
        }));

        // resume + stop ì¡°í•© ì¶©ëŒì„ í”¼í•˜ê¸° ìœ„í•´ redirect ì „í™˜ ì‹œ í˜„ì¬ ìŠ¤íŠ¸ë¦¼ resume ë¹„í™œì„±í™”
        setResumeEnabled(false);
        stopChat();

        const query = currentQueryRef.current;
        if (query) {
          abortControllerRef.current?.abort();
          const controller = new AbortController();
          abortControllerRef.current = controller;

          const currentQuery = query;

          queueMicrotask(() => {
            if (controller.signal.aborted) {
              logger.debug('[HybridAI] Job Queue redirect aborted');
              return;
            }
            // P1-10: refë¥¼ í†µí•´ ìµœì‹  asyncQuery ì°¸ì¡° (stale closure ë°©ì§€)
            asyncQueryRef.current
              .sendQuery(currentQuery)
              .then(() => {
                if (!controller.signal.aborted) {
                  logger.debug('[HybridAI] Job Queue redirect completed');
                }
              })
              .catch((error) => {
                if (!controller.signal.aborted) {
                  logger.error('[HybridAI] Job Queue redirect failed:', error);
                  setState((prev) => ({
                    ...prev,
                    isLoading: false,
                    error:
                      error instanceof Error
                        ? error.message
                        : 'Job Queue ì „í™˜ ì‹¤íŒ¨',
                  }));
                }
              });
          });
        }
        return;
      }

      // ì‚¬ìš©ì onData ì½œë°± í˜¸ì¶œ
      onData?.(part);
    },
    onError: async (error) => {
      const errorMessage = error.message || 'Unknown error';
      logger.error(
        `[HybridAI] useChat error (trace: ${traceIdRef.current}):`,
        errorMessage
      );

      // ì´ˆê¸° resume probe(ì•„ì§ ì‚¬ìš©ì ì¿¼ë¦¬ ì—†ìŒ)ì—ì„œ ë°œìƒí•˜ëŠ” ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ëŠ”
      // ì‚¬ìš©ì ì˜¤ë¥˜ë¡œ ìŠ¹ê²©í•˜ì§€ ì•Šê³  ë¬´ì‹œí•œë‹¤.
      const isResumeProbeWithoutUserQuery =
        !currentQueryRef.current &&
        /(failed to fetch|load failed|networkerror)/i.test(errorMessage);
      if (isResumeProbeWithoutUserQuery) {
        logger.debug(
          `[HybridAI] Ignoring resume probe error before first query (trace: ${traceIdRef.current})`
        );
        setState((prev) => ({ ...prev, isLoading: false }));
        return;
      }

      // Atomic check-and-set pattern to prevent double handling
      if (errorHandledRef.current) {
        logger.debug(
          '[HybridAI] onError skipped (already handled by onFinish)'
        );
        return;
      }
      errorHandledRef.current = true;

      // Streaming retry with exponential backoff
      const canRetry =
        isRetryableError(errorMessage) &&
        retryCountRef.current < streamRetryConfig.maxRetries;

      if (canRetry && currentQueryRef.current) {
        retryCountRef.current += 1;
        const delay = calculateRetryDelay(retryCountRef.current - 1);

        logger.info(
          `[HybridAI] Retrying stream (${retryCountRef.current}/${streamRetryConfig.maxRetries}) ` +
            `after ${delay}ms (trace: ${traceIdRef.current})`
        );

        setState((prev) => ({
          ...prev,
          warning: `ì¬ì—°ê²° ì¤‘... (${retryCountRef.current}/${streamRetryConfig.maxRetries})`,
        }));

        retryTimeoutRef.current = setTimeout(() => {
          retryTimeoutRef.current = null;
          // errorHandledRef is reset inside executeQuery (useQueryExecution.ts L99)
          const query = currentQueryRef.current;
          const attachments = pendingAttachmentsRef.current;
          if (query) {
            executeQuery(query, attachments || undefined, true);
          }
        }, delay);

        return;
      }

      retryCountRef.current = 0;

      setState((prev) => ({
        ...prev,
        isLoading: false,
        error: errorMessage || 'AI ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        warning: null,
        processingTime: 0,
      }));
    },
  });

  // ============================================================================
  // useAsyncAIQuery Hook (Job Queue Mode)
  // ============================================================================
  // P1-10 Fix: asyncQueryë¥¼ refì— ì €ì¥í•˜ì—¬ onData redirect í•¸ë“¤ëŸ¬ì˜ stale closure ë°©ì§€
  const asyncQueryRef = useRef<ReturnType<typeof useAsyncAIQuery>>(null!);

  const asyncQuery = useAsyncAIQuery({
    sessionId: sessionIdRef.current,
    onProgress: (progress) => {
      setState((prev) => ({ ...prev, progress }));
      onProgress?.(progress);
    },
    onResult: (result) => {
      setState((prev) => ({
        ...prev,
        isLoading: false,
        progress: null,
        clarification: null,
      }));
      onJobResult?.(result);

      if (result.success && result.response) {
        const messageWithRag = {
          id: generateMessageId('assistant'),
          role: 'assistant' as const,
          content: result.response,
          parts: [{ type: 'text' as const, text: result.response }],
          metadata:
            result.ragSources || result.traceId
              ? {
                  ...(result.ragSources && { ragSources: result.ragSources }),
                  ...(result.traceId && { traceId: result.traceId }),
                }
              : undefined,
        } as UIMessage;
        setMessages((prev) => [...prev, messageWithRag]);
      }
    },
    onError: (error) => {
      setState((prev) => ({
        ...prev,
        isLoading: false,
        error,
        clarification: null,
      }));
    },
  });

  // P1-10: refë¥¼ ìµœì‹  asyncQueryë¡œ ë™ê¸°í™”
  asyncQueryRef.current = asyncQuery;

  // ============================================================================
  // Computed Values
  // ============================================================================
  const isChatLoading =
    chatStatus === 'streaming' || chatStatus === 'submitted';
  const isLoading = state.isLoading || isChatLoading || asyncQuery.isLoading;

  // ============================================================================
  // Sub-Hooks: Query Execution (executeQuery + sendQuery)
  // ============================================================================
  const { executeQuery, sendQuery } = useQueryExecution({
    complexityThreshold,
    asyncQuery,
    sendMessage,
    onBeforeStreamingSend: () => {
      setResumeEnabled(true);
    },
    setMessages,
    setState,
    refs: {
      errorHandled: errorHandledRef,
      currentQuery: currentQueryRef,
      pendingQuery: pendingQueryRef,
      pendingAttachments: pendingAttachmentsRef,
    },
  });

  // ============================================================================
  // Sub-Hook: Clarification Handlers
  // ============================================================================
  const {
    selectClarification,
    submitCustomClarification,
    skipClarification,
    dismissClarification,
  } = useClarificationHandlers({
    pendingQueryRef,
    pendingAttachmentsRef,
    executeQuery,
    setState,
  });

  // ============================================================================
  // Sub-Hook: Control Functions
  // ============================================================================
  const { stop, cancel, reset, previewComplexity } = useQueryControls({
    currentMode: state.mode,
    asyncQuery,
    stopChat,
    onUserAbort: () => {
      setResumeEnabled(false);
    },
    onReset: () => {
      setResumeEnabled(true);
    },
    setMessages,
    setState,
    refs: {
      abortController: abortControllerRef,
      retryTimeout: retryTimeoutRef,
      retryCount: retryCountRef,
      traceId: traceIdRef,
      pendingQuery: pendingQueryRef,
      pendingAttachments: pendingAttachmentsRef,
      currentQuery: currentQueryRef,
    },
  });

  // ============================================================================
  // Cleanup on Unmount
  // ============================================================================
  useEffect(() => {
    return () => {
      abortControllerRef.current?.abort();
      abortControllerRef.current = null;
      if (retryTimeoutRef.current) {
        clearTimeout(retryTimeoutRef.current);
        retryTimeoutRef.current = null;
      }
    };
  }, []);

  // ============================================================================
  // Return
  // ============================================================================
  return {
    sendQuery,
    executeQuery,
    state,
    messages,
    setMessages,
    progressPercent: state.progress?.progress ?? asyncQuery.progressPercent,
    progressMessage: state.progress?.message ?? asyncQuery.progressMessage,
    isLoading,
    stop,
    cancel,
    reset,
    currentMode: state.mode,
    previewComplexity,
    // Clarification functions
    selectClarification,
    submitCustomClarification,
    skipClarification,
    dismissClarification,
  };
}

export default useHybridAIQuery;

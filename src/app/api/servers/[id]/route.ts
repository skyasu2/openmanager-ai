import type { NextRequest } from 'next/server';
import { NextResponse } from 'next/server';
import { withAuth } from '@/lib/auth/api-auth';
import type { ServerHistory } from '@/schemas/server-schemas/server-details.schema';
import {
  metricsProvider,
  type ServerMetrics,
} from '@/services/metrics/MetricsProvider';
import { getServerMonitoringService } from '@/services/monitoring';
import debug from '@/utils/debug';

/**
 * ğŸ“Š MetricsProvider ê¸°ë°˜ ê°œë³„ ì„œë²„ ì •ë³´ ì¡°íšŒ API
 * GET /api/servers/[id]
 * íŠ¹ì • ì„œë²„ì˜ ìƒì„¸ ì •ë³´ ë° íˆìŠ¤í† ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤ (OTel + hourly-data 2-tier)
 */
export const GET = withAuth(
  async (
    request: NextRequest,
    { params }: { params: Promise<{ id: string }> }
  ) => {
    const startTime = Date.now();

    try {
      const { id } = await params;
      const { searchParams } = new URL(request.url);
      const includeHistory = searchParams.get('history') === 'true';
      const range = searchParams.get('range') || '24h';
      const format = searchParams.get('format') || 'enhanced'; // enhanced | legacy | prometheus
      const includeMetrics = searchParams.get('include_metrics') === 'true';
      const includePatterns = searchParams.get('include_patterns') === 'true';

      debug.log(
        `ğŸ“Š ì„œë²„ [${id}] ì •ë³´ ì¡°íšŒ: history=${includeHistory}, range=${range}, format=${format}`
      );

      // MetricsProviderì—ì„œ ì„œë²„ ì°¾ê¸° (ID ë˜ëŠ” hostnameìœ¼ë¡œ ê²€ìƒ‰)
      let metric = metricsProvider.getServerMetrics(id);

      // hostnameìœ¼ë¡œë„ ê²€ìƒ‰ ì‹œë„
      if (!metric) {
        const allMetrics = metricsProvider.getAllServerMetrics();
        metric =
          allMetrics.find((m) => m.hostname === id || m.serverId === id) ??
          null;
      }

      if (!metric) {
        const allMetrics = metricsProvider.getAllServerMetrics();
        const availableServers = allMetrics.slice(0, 10).map((m) => ({
          id: m.serverId,
          hostname: m.hostname ?? m.serverId,
        }));

        return NextResponse.json(
          {
            success: false,
            error: 'Server not found',
            message: `ì„œë²„ '${id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤`,
            available_servers: availableServers,
            timestamp: new Date().toISOString(),
          },
          { status: 404 }
        );
      }

      debug.log(
        `âœ… ì„œë²„ [${id}] ë°œê²¬: ${metric.hostname ?? metric.serverId} (${metric.environment ?? 'unknown'}/${metric.serverType})`
      );

      // ServerMonitoringServiceë¥¼ í†µí•œ ê°€ê³µëœ ë°ì´í„°
      const service = getServerMonitoringService();
      const processed = service.getProcessedServer(metric.serverId);
      const specs = processed?.specs
        ? { ...processed.specs, os: processed.osLabel }
        : undefined;
      const uptimeSeconds = processed?.uptimeSeconds ?? 0;

      // 3. ì‘ë‹µ í˜•ì‹ì— ë”°ë¥¸ ì²˜ë¦¬
      if (format === 'prometheus') {
        // ğŸ—‘ï¸ Prometheus í˜•ì‹ì€ ë” ì´ìƒ ì§€ì›í•˜ì§€ ì•ŠìŒ
        return NextResponse.json(
          {
            error: 'Prometheus format is no longer supported',
            message: 'Please use JSON format instead',
            server_id: metric.serverId,
          },
          { status: 410 } // Gone
        );
      } else if (format === 'legacy') {
        // ë ˆê±°ì‹œ í˜•ì‹
        const legacyServer = {
          id: metric.serverId,
          hostname: metric.hostname ?? metric.serverId,
          ip: processed?.ip,
          name: `OpenManager-${metric.serverId}`,
          type: metric.serverType,
          environment: metric.environment ?? 'onpremise',
          location: getLocationByEnvironment(metric.environment ?? 'onpremise'),
          provider: getProviderByEnvironment(metric.environment ?? 'onpremise'),
          status: metric.status,
          cpu: Math.round(metric.cpu),
          memory: Math.round(metric.memory),
          disk: Math.round(metric.disk),
          uptime: formatUptime(uptimeSeconds),
          lastUpdate: new Date(metric.timestamp),
          alerts: 0,
          services: processed?.services ?? [],
          specs,
          os: specs?.os ?? processed?.osLabel ?? 'Unknown',
          metrics: {
            cpu: Math.round(metric.cpu),
            memory: Math.round(metric.memory),
            disk: Math.round(metric.disk),
            network_in: processed?.networkIn ?? 0,
            network_out: processed?.networkOut ?? 0,
            response_time: processed?.responseTimeMs ?? 0,
          },
        };

        // íˆìŠ¤í† ë¦¬ ë°ì´í„° ìƒì„± (ìš”ì²­ì‹œ)
        let history = null;
        if (includeHistory) {
          history = generateServerHistory(metric, range);
        }

        return NextResponse.json(
          {
            success: true,
            server: legacyServer,
            history,
            meta: {
              format: 'legacy',
              include_history: includeHistory,
              range,
              timestamp: new Date().toISOString(),
              processing_time_ms: Date.now() - startTime,
            },
          },
          {
            headers: {
              // Legacy í˜•ì‹ë„ 30ì´ˆ ìºì‹±
              'Cache-Control': 'public, s-maxage=30, stale-while-revalidate=60',
              'CDN-Cache-Control': 'public, s-maxage=30',
              'Vercel-CDN-Cache-Control': 'public, s-maxage=30',
            },
          }
        );
      } else {
        // Enhanced í˜•ì‹ (ê¸°ë³¸)
        const enhancedResponse = {
          // ê¸°ë³¸ ì„œë²„ ì •ë³´
          server_info: {
            id: metric.serverId,
            hostname: metric.hostname ?? metric.serverId,
            environment: metric.environment ?? 'unknown',
            role: metric.serverType,
            status: metric.status,
            uptime: formatUptime(uptimeSeconds),
            last_updated: metric.timestamp,
          },

          // í˜„ì¬ ë©”íŠ¸ë¦­ (ServerMonitoringService ê¸°ë°˜)
          current_metrics: {
            cpu_usage: metric.cpu,
            memory_usage: metric.memory,
            disk_usage: metric.disk,
            network_in: processed?.networkIn ?? 0,
            network_out: processed?.networkOut ?? 0,
            response_time: processed?.responseTimeMs ?? 0,
          },

          // ë¦¬ì†ŒìŠ¤ ì •ë³´ (MetricsProvider nodeInfo ê¸°ë°˜)
          resources: specs,
          network: {
            hostname: metric.hostname ?? metric.serverId,
            ip: processed?.ip,
            interface: 'eth0',
          },

          // ì•ŒëŒ ì •ë³´
          alerts: processed?.alerts ?? [],

          // ì„œë¹„ìŠ¤ ì •ë³´
          services: processed?.services ?? [],
        };

        // íŒ¨í„´ ì •ë³´ í¬í•¨ (ìš”ì²­ì‹œ)
        let patternInfo: unknown;
        let correlationMetrics: unknown;
        if (includePatterns) {
          patternInfo = null;
          correlationMetrics = null;
        }

        // íˆìŠ¤í† ë¦¬ ë°ì´í„° (ìš”ì²­ì‹œ)
        let history: ServerHistory | undefined;
        if (includeHistory) {
          history = generateServerHistory(metric, range);
        }

        // ë©”íƒ€ë°ì´í„°
        const response = {
          meta: {
            request_info: {
              server_id: id,
              format,
              include_history: includeHistory,
              include_metrics: includeMetrics,
              include_patterns: includePatterns,
              range,
              processing_time_ms: Date.now() - startTime,
              timestamp: new Date().toISOString(),
            },
            dataSource: 'hourly-scenarios',
            scenario: 'production',
          },
          data: {
            ...enhancedResponse,
            pattern_info: patternInfo,
            correlation_metrics: correlationMetrics,
            history,
          },
        };

        return NextResponse.json(response, {
          headers: {
            'X-Server-Id': metric.serverId,
            'X-Hostname': metric.hostname ?? metric.serverId,
            'X-Server-Status': metric.status,
            'X-Processing-Time-Ms': (Date.now() - startTime).toString(),
            // ê°œë³„ ì„œë²„ ì •ë³´ëŠ” 30ì´ˆ ìºì‹±
            'Cache-Control': 'public, s-maxage=30, stale-while-revalidate=60',
            'CDN-Cache-Control': 'public, s-maxage=30',
            'Vercel-CDN-Cache-Control': 'public, s-maxage=30',
          },
        });
      }
    } catch (error) {
      debug.error(`âŒ ì„œë²„ [${(await params).id}] ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨:`, error);

      return NextResponse.json(
        {
          success: false,
          error: 'Server information retrieval failed',
          message:
            error instanceof Error
              ? error.message
              : 'ì„œë²„ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
          timestamp: new Date().toISOString(),
        },
        { status: 500 }
      );
    }
  }
);

/**
 * ğŸŒ í™˜ê²½ë³„ ìœ„ì¹˜ ë°˜í™˜
 */
function getLocationByEnvironment(environment: string): string {
  const locationMap: Record<string, string> = {
    aws: 'AWS Seoul (ap-northeast-2)',
    azure: 'Azure Korea Central',
    gcp: 'GCP Seoul (asia-northeast3)',
    container: 'Container Cluster',
    idc: 'Seoul IDC',
    vdi: 'Virtual Desktop Infrastructure',
    onpremise: 'On-Premise Seoul DC1',
  };
  return locationMap[environment] || 'Unknown Location';
}

/**
 * ğŸ¢ í™˜ê²½ë³„ ì œê³µì ë°˜í™˜
 */
function getProviderByEnvironment(environment: string): string {
  const providerMap: Record<string, string> = {
    aws: 'Amazon Web Services',
    azure: 'Microsoft Azure',
    gcp: 'Google Cloud Platform',
    kubernetes: 'Kubernetes',
    idc: 'Internet Data Center',
    vdi: 'VMware vSphere',
    onpremise: 'On-Premise',
  };
  return providerMap[environment] || 'Unknown Provider';
}

/**
 * â° ì—…íƒ€ì„ í¬ë§·íŒ…
 */
function formatUptime(uptimeSeconds: number): string {
  const days = Math.floor(uptimeSeconds / (24 * 3600));
  const hours = Math.floor((uptimeSeconds % (24 * 3600)) / 3600);
  const minutes = Math.floor((uptimeSeconds % 3600) / 60);

  return `${days}d ${hours}h ${minutes}m`;
}

/**
 * ğŸ“ˆ ì„œë²„ íˆìŠ¤í† ë¦¬ (í˜„ì¬ ìŠ¤ëƒ…ìƒ·ë§Œ ë°˜í™˜)
 * ì‹¤ì œ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ í˜„ì¬ ë©”íŠ¸ë¦­ì„ ë‹¨ì¼ ë°ì´í„° í¬ì¸íŠ¸ë¡œ ë°˜í™˜.
 * Math.random/Math.sin ê¸°ë°˜ fabrication ì œê±°ë¨.
 */
function generateServerHistory(
  metric: ServerMetrics,
  range: string
): ServerHistory {
  const now = new Date().toISOString();

  return {
    time_range: range,
    start_time: now,
    end_time: now,
    interval_ms: 0,
    data_points: [
      {
        timestamp: now,
        metrics: {
          cpu_usage: metric.cpu,
          memory_usage: metric.memory,
          disk_usage: metric.disk,
          network_in: metric.network,
          network_out: metric.network,
          response_time: metric.responseTimeMs ?? 0,
        },
      },
    ],
  };
}

/**
 * Scenario-based log generation in syslog format.
 *
 * Generates realistic logs from various sources (nginx, docker, kernel,
 * systemd, mysqld, redis, etc.) based on the current scenario and metrics.
 *
 * @see scenario-loader.ts - Main orchestration facade
 */

import type { ScenarioLogEntry } from '@/services/scenario/scenario-types';

/**
 * ðŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ë¡œê·¸ ìƒì„± (ì‹¤ì œ syslog í˜•ì‹)
 *
 * ìƒìš© ë¡œê·¸ ìˆ˜ì§‘ í”„ë¡œê·¸ëž¨ê³¼ ìœ ì‚¬í•œ í˜•íƒœì˜ ë¡œê·¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
 * - syslog í˜•ì‹: hostname process[pid]: message
 * - ë‹¤ì–‘í•œ ì†ŒìŠ¤: nginx, docker, kernel, systemd, mysqld, redis ë“±
 * - ì‹¤ì œ ì—ëŸ¬ ì½”ë“œ í¬í•¨
 *
 * @param scenario - í˜„ìž¬ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…
 * @param serverMetrics - ì„œë²„ ë©”íŠ¸ë¦­ (cpu, memory, disk, network)
 * @param serverId - ì„œë²„ ID (hostnameìœ¼ë¡œ ì‚¬ìš©)
 * @returns ë¡œê·¸ ë°°ì—´
 */
export function generateScenarioLogs(
  scenario: string,
  serverMetrics: { cpu: number; memory: number; disk: number; network: number },
  serverId: string
): ScenarioLogEntry[] {
  const logs: ScenarioLogEntry[] = [];

  const now = new Date();
  const { cpu, memory, disk, network } = serverMetrics;
  const hostname = serverId.split('.')[0] || serverId;

  // ëžœë¤ PID ìƒì„± í—¬í¼
  const pid = (base: number) => base + Math.floor(Math.random() * 1000);

  // ì‹œë‚˜ë¦¬ì˜¤ í‚¤ì›Œë“œ ë§¤ì¹­
  const scenarioLower = scenario.toLowerCase();

  // 1. ì •ìƒ ìš´ì˜ ì‹œë‚˜ë¦¬ì˜¤
  if (scenarioLower.includes('ì •ìƒ')) {
    logs.push({
      timestamp: new Date(now.getTime() - 30000).toISOString(),
      level: 'info',
      message: `${hostname} systemd[1]: Started Daily apt download activities.`,
      source: 'systemd',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 45000).toISOString(),
      level: 'info',
      message: `${hostname} CRON[${pid(20000)}]: (root) CMD (/usr/lib/apt/apt.systemd.daily install)`,
      source: 'cron',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 60000).toISOString(),
      level: 'info',
      message: `${hostname} nginx[${pid(1000)}]: 10.0.0.1 - - "GET /health HTTP/1.1" 200 15 "-" "kube-probe/1.28"`,
      source: 'nginx',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 90000).toISOString(),
      level: 'info',
      message: `${hostname} dockerd[${pid(800)}]: time="2026-01-03T10:00:00.000000000Z" level=info msg="Container health status: healthy"`,
      source: 'docker',
    });
  }

  // 2. CPU ê³¼ë¶€í•˜ ì‹œë‚˜ë¦¬ì˜¤
  if (
    scenarioLower.includes('cpu') ||
    scenarioLower.includes('ê³¼ë¶€í•˜') ||
    scenarioLower.includes('api')
  ) {
    logs.push({
      timestamp: new Date(now.getTime() - 15000).toISOString(),
      level: 'error',
      message: `${hostname} kernel: [${pid(50000)}.${pid(100)}] CPU${Math.floor(Math.random() * 8)}: Package temperature above threshold, cpu clock throttled`,
      source: 'kernel',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 30000).toISOString(),
      level: 'error',
      message: `${hostname} nginx[${pid(1000)}]: upstream timed out (110: Connection timed out) while reading response header from upstream`,
      source: 'nginx',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 45000).toISOString(),
      level: 'warn',
      message: `${hostname} java[${pid(5000)}]: GC overhead limit exceeded - heap usage at ${cpu.toFixed(0)}%`,
      source: 'java',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 60000).toISOString(),
      level: 'warn',
      message: `${hostname} haproxy[${pid(2000)}]: backend api_servers has no server available! (qcur=${Math.floor(cpu * 2)})`,
      source: 'haproxy',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 90000).toISOString(),
      level: 'info',
      message: `${hostname} systemd[1]: node-exporter.service: Watchdog timeout (limit 30s)!`,
      source: 'systemd',
    });
  }

  // 3. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì‹œë‚˜ë¦¬ì˜¤
  if (
    scenarioLower.includes('ë©”ëª¨ë¦¬') ||
    scenarioLower.includes('memory') ||
    scenarioLower.includes('oom') ||
    scenarioLower.includes('redis') ||
    scenarioLower.includes('ìºì‹œ')
  ) {
    logs.push({
      timestamp: new Date(now.getTime() - 10000).toISOString(),
      level: 'error',
      message: `${hostname} kernel: Out of memory: Killed process ${pid(10000)} (java) total-vm:${Math.floor(memory * 100)}kB, anon-rss:${Math.floor(memory * 80)}kB`,
      source: 'kernel',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 25000).toISOString(),
      level: 'error',
      message: `${hostname} redis-server[${pid(3000)}]: # WARNING: Memory usage ${memory.toFixed(0)}% of max. Consider increasing maxmemory.`,
      source: 'redis',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 40000).toISOString(),
      level: 'warn',
      message: `${hostname} dockerd[${pid(800)}]: container ${serverId.substring(0, 12)} OOMKilled=true (memory limit: 2GiB)`,
      source: 'docker',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 55000).toISOString(),
      level: 'warn',
      message: `${hostname} java[${pid(5000)}]: java.lang.OutOfMemoryError: GC overhead limit exceeded`,
      source: 'java',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 80000).toISOString(),
      level: 'info',
      message: `${hostname} java[${pid(5000)}]: [GC (Allocation Failure) ${Math.floor(memory * 50)}K->${Math.floor(memory * 30)}K(${Math.floor(memory * 100)}K), 0.${pid(100)} secs]`,
      source: 'java',
    });
  }

  // 4. ë””ìŠ¤í¬ I/O ì‹œë‚˜ë¦¬ì˜¤
  if (
    scenarioLower.includes('ë””ìŠ¤í¬') ||
    scenarioLower.includes('disk') ||
    scenarioLower.includes('ë°±ì—…') ||
    scenarioLower.includes('i/o')
  ) {
    logs.push({
      timestamp: new Date(now.getTime() - 20000).toISOString(),
      level: 'error',
      message: `${hostname} kernel: [${pid(80000)}.${pid(100)}] EXT4-fs warning (device sda1): ext4_dx_add_entry:2461: Directory (ino: ${pid(100000)}) index full, reach max htree level :2`,
      source: 'kernel',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 35000).toISOString(),
      level: 'error',
      message: `${hostname} mysqld[${pid(4000)}]: [ERROR] InnoDB: Write to file ./ib_logfile0 failed at offset ${pid(1000000)}. ${disk.toFixed(0)}% disk used.`,
      source: 'mysql',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 50000).toISOString(),
      level: 'warn',
      message: `${hostname} rsync[${pid(15000)}]: rsync: write failed on "/backup/db-${hostname}.sql": No space left on device (28)`,
      source: 'rsync',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 70000).toISOString(),
      level: 'info',
      message: `${hostname} systemd[1]: Starting Daily Backup Service...`,
      source: 'systemd',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 120000).toISOString(),
      level: 'info',
      message: `${hostname} pg_dump[${pid(18000)}]: pg_dump: archiving data for table "public.logs" (${Math.floor(disk * 10)}MB)`,
      source: 'postgres',
    });
  }

  // 5. ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ì‹œë‚˜ë¦¬ì˜¤
  if (
    scenarioLower.includes('ë„¤íŠ¸ì›Œí¬') ||
    scenarioLower.includes('network') ||
    scenarioLower.includes('íŒ¨í‚·') ||
    scenarioLower.includes('lb') ||
    scenarioLower.includes('ë¡œë“œë°¸ëŸ°ì„œ')
  ) {
    logs.push({
      timestamp: new Date(now.getTime() - 12000).toISOString(),
      level: 'error',
      message: `${hostname} kernel: [${pid(90000)}.${pid(100)}] nf_conntrack: nf_conntrack: table full, dropping packet`,
      source: 'kernel',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 28000).toISOString(),
      level: 'error',
      message: `${hostname} nginx[${pid(1000)}]: connect() failed (111: Connection refused) while connecting to upstream`,
      source: 'nginx',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 42000).toISOString(),
      level: 'warn',
      message: `${hostname} haproxy[${pid(2000)}]: Server api_backend/server1 is DOWN, reason: Layer4 timeout, check duration: 5001ms`,
      source: 'haproxy',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 65000).toISOString(),
      level: 'warn',
      message: `${hostname} kernel: [${pid(90000)}.${pid(100)}] TCP: request_sock_TCP: Possible SYN flooding on port 80. Sending cookies.`,
      source: 'kernel',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 95000).toISOString(),
      level: 'info',
      message: `${hostname} sshd[${pid(22000)}]: Received disconnect from 10.0.0.${Math.floor(network / 10)} port ${pid(40000)}: 11: disconnected by user`,
      source: 'sshd',
    });
  }

  // ê¸°ë³¸ ë¡œê·¸ (ì‹œë‚˜ë¦¬ì˜¤ ë§¤ì¹­ ì—†ëŠ” ê²½ìš°)
  if (logs.length === 0) {
    logs.push({
      timestamp: new Date(now.getTime() - 30000).toISOString(),
      level: 'info',
      message: `${hostname} systemd[1]: Started Session ${pid(100)} of user root.`,
      source: 'systemd',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 60000).toISOString(),
      level: 'info',
      message: `${hostname} nginx[${pid(1000)}]: 10.0.0.1 - - "GET / HTTP/1.1" 200 612 "-" "curl/7.68.0"`,
      source: 'nginx',
    });
  }

  // ì‹œê°„ìˆœ ì •ë ¬ (ìµœì‹  ë¨¼ì €)
  return logs.sort(
    (a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime()
  );
}

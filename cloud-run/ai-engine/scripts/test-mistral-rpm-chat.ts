/**
 * Mistral Free Tier RPM ì‹¤ì¸¡ í…ŒìŠ¤íŠ¸ â€” Chat (LLM) ì—”ë“œí¬ì¸íŠ¸
 *
 * Embeddingì€ RPM ì œí•œ ì—†ì´ ë™ì‘í–ˆìœ¼ë¯€ë¡œ,
 * Chat (generateText) ì—”ë“œí¬ì¸íŠ¸ì˜ ì‹¤ì œ RPM í•œë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
 *
 * ì‹¤í–‰: cd cloud-run/ai-engine && npx tsx scripts/test-mistral-rpm-chat.ts
 */

import { createMistral } from '@ai-sdk/mistral';
import { generateText } from 'ai';

// ============================================================================
// Configuration
// ============================================================================

const MAX_REQUESTS = 15; // Chatì€ ë” ëŠë¦¬ë¯€ë¡œ 15íšŒ
const INTERVAL_MS = 0; // ëŒ€ê¸° ì—†ì´ ì—°ì†
const SYSTEM_PROMPT = 'Reply in exactly one short sentence.';
const USER_PROMPT = 'What is CPU utilization?';

// ============================================================================
// Main
// ============================================================================

async function main() {
  const apiKey = process.env.MISTRAL_API_KEY;
  if (!apiKey) {
    console.error('âŒ MISTRAL_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    process.exit(1);
  }

  const mistral = createMistral({ apiKey });

  console.log('ğŸ§ª Mistral Free Tier RPM ì‹¤ì¸¡ â€” Chat (LLM) í…ŒìŠ¤íŠ¸');
  console.log(`   ëª¨ë¸: mistral-small-latest`);
  console.log(`   ìµœëŒ€ ìš”ì²­: ${MAX_REQUESTS}íšŒ`);
  console.log(`   ê°„ê²©: ${INTERVAL_MS}ms (burst)`);
  console.log('â”€'.repeat(60));

  const testStart = Date.now();
  let successCount = 0;
  let rateLimitCount = 0;

  for (let i = 1; i <= MAX_REQUESTS; i++) {
    const reqStart = Date.now();
    const elapsed = ((reqStart - testStart) / 1000).toFixed(1);

    try {
      const result = await generateText({
        model: mistral('mistral-small-latest'),
        messages: [
          { role: 'system', content: SYSTEM_PROMPT },
          { role: 'user', content: `${USER_PROMPT} [${i}]` },
        ],
        maxOutputTokens: 50,
        temperature: 0.1,
        maxRetries: 0, // ì¬ì‹œë„ ì—†ì´ raw ì—ëŸ¬ í™•ì¸
      });

      const latencyMs = Date.now() - reqStart;
      successCount++;

      const text = result.text.substring(0, 60).replace(/\n/g, ' ');
      console.log(
        `  âœ… #${String(i).padStart(2, '0')} | ${elapsed}s | ${latencyMs}ms | "${text}..." | ëˆ„ì : ${successCount}`
      );
    } catch (error) {
      const latencyMs = Date.now() - reqStart;
      const message = error instanceof Error ? error.message : String(error);
      const is429 = message.includes('429') || message.toLowerCase().includes('rate limit') || message.includes('Too many requests');

      if (is429) {
        rateLimitCount++;
        console.log(
          `  ğŸš« #${String(i).padStart(2, '0')} | ${elapsed}s | ${latencyMs}ms | âš¡ RATE LIMIT (429) â€” íšŸìˆ˜: ${rateLimitCount}`
        );
      } else {
        console.log(
          `  âŒ #${String(i).padStart(2, '0')} | ${elapsed}s | ${latencyMs}ms | ${message.substring(0, 100)}`
        );
      }

      if (rateLimitCount >= 5) {
        console.log(`\n  â¹ï¸  Rate limit 5íšŒ ë°˜ë³µ â€” í…ŒìŠ¤íŠ¸ ì¢…ë£Œ`);
        break;
      }
    }

    if (i < MAX_REQUESTS && INTERVAL_MS > 0) {
      await new Promise((resolve) => setTimeout(resolve, INTERVAL_MS));
    }
  }

  // Summary
  const totalDuration = ((Date.now() - testStart) / 1000).toFixed(1);
  console.log('\n' + 'â•'.repeat(60));
  console.log('ğŸ“Š Chat (LLM) RPM í…ŒìŠ¤íŠ¸ ê²°ê³¼');
  console.log('â•'.repeat(60));
  console.log(`  ì´ ìš”ì²­:        ${successCount + rateLimitCount}íšŒ`);
  console.log(`  ì„±ê³µ:           ${successCount}íšŒ`);
  console.log(`  Rate Limit:     ${rateLimitCount}íšŒ`);
  console.log(`  ì´ ì†Œìš” ì‹œê°„:   ${totalDuration}s`);

  if (rateLimitCount > 0) {
    console.log(`  â†’ Chat RPM ì‹¤ì¸¡ â‰ˆ ${successCount}íšŒ/ë¶„ ì´ë‚´`);
  } else {
    console.log(`  âœ… ${MAX_REQUESTS}íšŒ ëª¨ë‘ ì„±ê³µ â€” Chat RPM > ${MAX_REQUESTS}`);
  }
  console.log('â•'.repeat(60));
}

main().catch(console.error);

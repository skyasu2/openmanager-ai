/**
 * LlamaIndex.TS RAG Service
 *
 * Replaces custom GraphRAG implementation with LlamaIndex.TS open-source library.
 * Uses Mistral AI for triplet extraction and Supabase pgVector for storage.
 *
 * @version 1.0.0
 * @created 2025-12-31
 * @replaces graph-rag-service.ts (custom implementation)
 */

import { generateText, type LanguageModel } from 'ai';
import { createClient, SupabaseClient } from '@supabase/supabase-js';
import { getSupabaseConfig } from './config-parser';
import { getCerebrasModel } from '../services/ai-sdk/model-provider-core';
import { logger } from './logger';
import {
  hybridTextVectorSearch,
  type HybridSearchResult as TextSearchResult,
} from './hybrid-text-search';
import {
  extractRelationshipsFromKnowledgeBase,
  fetchRelatedKnowledgeFromGraph,
  type ExtractionResult,
} from './llamaindex-rag-relations';
import {
  mergeDeduplicateAndRankResults,
  traverseAndFetchGraphNodes,
} from './llamaindex-rag-graph';
import type {
  KnowledgeTriplet,
  LlamaIndexSearchResult,
  LlamaIndexStats,
} from './llamaindex-rag-types';
export type {
  KnowledgeTriplet,
  LlamaIndexSearchResult,
  LlamaIndexStats,
} from './llamaindex-rag-types';

// ============================================================================
// Configuration
// ============================================================================

let isInitialized = false;
let supabaseClient: SupabaseClient | null = null;
let llamaLlm: LanguageModel | null = null;

/**
 * Initialize LlamaIndex with Cerebras AI (gpt-oss-120b)
 */
export async function initializeLlamaIndex(): Promise<boolean> {
  if (isInitialized) return true;

  try {
    // Configure Cerebras LLM instance (120B MoE, 1M TPD)
    llamaLlm = getCerebrasModel('gpt-oss-120b');

    // Initialize Supabase client
    const supabaseConfig = getSupabaseConfig();
    if (supabaseConfig) {
      supabaseClient = createClient(
        supabaseConfig.url,
        supabaseConfig.serviceRoleKey
      );
    }

    isInitialized = true;
    console.log('‚úÖ [LlamaIndex] Initialized with Cerebras AI (gpt-oss-120b)');
    return true;
  } catch (error) {
    logger.error('‚ùå [LlamaIndex] Initialization failed:', error);
    return false;
  }
}

// ============================================================================
// Triplet Extraction (Knowledge Graph)
// ============================================================================

/**
 * Extract knowledge triplets from text using LLM
 * Replaces heuristic-based detection with LLM-powered extraction
 */
export async function extractTriplets(
  text: string,
  maxTriplets: number = 10
): Promise<KnowledgeTriplet[]> {
  await initializeLlamaIndex();

  if (!llamaLlm) {
    logger.warn('‚ö†Ô∏è [LlamaIndex] LLM not configured');
    return [];
  }

  try {
    const prompt = `
Extract up to ${maxTriplets} knowledge triplets from the following text.
Each triplet should be in the format: (subject, predicate, object)

Text:
${text}

Output as JSON array:
[{"subject": "...", "predicate": "...", "object": "...", "confidence": 0.0-1.0}]

Only output the JSON array, no other text.
`;

    const { text: responseRaw } = await generateText({
      model: llamaLlm,
      prompt,
      maxOutputTokens: 500,
    });
    const responseText = responseRaw.trim();

    // Parse JSON response
    const jsonMatch = responseText.match(/\[[\s\S]*\]/);
    if (!jsonMatch) {
      logger.warn('‚ö†Ô∏è [LlamaIndex] Failed to parse triplets JSON');
      return [];
    }

    const triplets = JSON.parse(jsonMatch[0]) as KnowledgeTriplet[];
    console.log(`üìä [LlamaIndex] Extracted ${triplets.length} triplets`);
    return triplets;
  } catch (error) {
    logger.error('‚ùå [LlamaIndex] Triplet extraction failed:', error);
    return [];
  }
}

// ============================================================================
// Vector Search with Supabase pgVector
// ============================================================================

/**
 * Search knowledge base using vector similarity
 * Uses existing Supabase pgVector infrastructure
 */
export async function searchKnowledgeBase(
  query: string,
  options: {
    similarityThreshold?: number;
    maxResults?: number;
    category?: string;
  } = {}
): Promise<LlamaIndexSearchResult[]> {
  await initializeLlamaIndex();

  const {
    similarityThreshold = 0.3,
    maxResults = 10,
    category,
  } = options;

  if (!supabaseClient) {
    logger.warn('‚ö†Ô∏è [LlamaIndex] Supabase not available');
    return [];
  }

  try {
    // Use Supabase RPC for vector search (embeddings generated by Supabase)
    const { data, error } = await supabaseClient.rpc('match_knowledge_base', {
      query_text: query,
      match_threshold: similarityThreshold,
      match_count: maxResults,
    });

    if (error) throw error;

    const normalizedCategory = category?.trim().toLowerCase();
    const filteredRows = (data || [])
      .filter((row: Record<string, unknown>) => {
        if (!normalizedCategory) return true;
        return String(row.category || '').toLowerCase() === normalizedCategory;
      })
      .slice(0, maxResults);

    return filteredRows.map((row: Record<string, unknown>) => ({
      id: String(row.id),
      title: String(row.title || ''),
      content: String(row.content || ''),
      category: row.category ? String(row.category) : undefined,
      score: Number(row.similarity || 0),
      sourceType: 'vector' as const,
      hopDistance: 0,
      metadata: row.metadata as Record<string, unknown>,
    }));
  } catch (error) {
    logger.error('‚ùå [LlamaIndex] Search failed:', error);
    return [];
  }
}

// ============================================================================
// Hybrid Search (Vector + Knowledge Graph)
// ============================================================================

/**
 * Hybrid search combining vector similarity and knowledge graph traversal
 * Leverages LlamaIndex's built-in hybrid search capabilities
 */
export async function hybridSearch(
  query: string,
  options: {
    similarityThreshold?: number;
    maxVectorResults?: number;
    maxGraphHops?: number;
    maxTotalResults?: number;
  } = {}
): Promise<LlamaIndexSearchResult[]> {
  await initializeLlamaIndex();

  const {
    similarityThreshold = 0.3,
    maxVectorResults = 5,
    maxGraphHops = 2,
    maxTotalResults = 15,
  } = options;

  if (!supabaseClient) {
    logger.warn('‚ö†Ô∏è [LlamaIndex] Supabase not available');
    return [];
  }

  try {
    // 1. Vector search
    const vectorResults = await searchKnowledgeBase(query, {
      similarityThreshold,
      maxResults: maxVectorResults,
    });

    // 2. Graph traversal from vector results
    const graphResults = await traverseAndFetchGraphNodes(
      supabaseClient!, vectorResults, maxGraphHops
    );

    return mergeDeduplicateAndRankResults(vectorResults, graphResults, maxTotalResults);
  } catch (error) {
    logger.error('‚ùå [LlamaIndex] Hybrid search failed:', error);
    return [];
  }
}

// ============================================================================
// Index Documents
// ============================================================================

/**
 * Index new documents into the knowledge base
 * Uses LlamaIndex for document processing and embedding
 */
export async function indexDocuments(
  documents: Array<{ text: string; metadata?: Record<string, unknown> }>
): Promise<{ success: boolean; indexed: number }> {
  await initializeLlamaIndex();

  if (!supabaseClient) {
    return { success: false, indexed: 0 };
  }

  try {
    let indexed = 0;

    for (const doc of documents) {
      // 1. Extract triplets for knowledge graph
      const triplets = await extractTriplets(doc.text, 5);

      // 2. Store in Supabase (embeddings handled by existing infrastructure)
      const { error } = await supabaseClient.from('knowledge_base').insert({
        content: doc.text,
        title: doc.metadata?.title || 'Untitled',
        category: doc.metadata?.category || 'general',
        tags: doc.metadata?.tags || [],
        metadata: {
          ...doc.metadata,
          triplets: triplets, // Store extracted triplets
          indexed_at: new Date().toISOString(),
          indexed_by: 'llamaindex',
        },
      });

      if (!error) indexed++;
    }

    console.log(`‚úÖ [LlamaIndex] Indexed ${indexed}/${documents.length} documents`);
    return { success: true, indexed };
  } catch (error) {
    logger.error('‚ùå [LlamaIndex] Indexing failed:', error);
    return { success: false, indexed: 0 };
  }
}

// ============================================================================
// Stats
// ============================================================================

/**
 * Get LlamaIndex RAG statistics
 */
export async function getStats(): Promise<LlamaIndexStats | null> {
  if (!supabaseClient) return null;

  try {
    const [docsResult, relsResult] = await Promise.all([
      supabaseClient.from('knowledge_base').select('id', { count: 'exact', head: true }),
      supabaseClient.from('knowledge_relationships').select('id, created_at', { count: 'exact' }).order('created_at', { ascending: false }).limit(1),
    ]);

    return {
      totalDocuments: docsResult.count || 0,
      totalTriplets: relsResult.count || 0,
      lastIndexed: relsResult.data?.[0]?.created_at || null,
    };
  } catch (error) {
    logger.error('‚ùå [LlamaIndex] Stats fetch failed:', error);
    return null;
  }
}

// ============================================================================
// Backward Compatibility Exports
// ============================================================================

/**
 * Backward-compatible hybridGraphSearch that accepts embedding array
 * Used by reporter-tools.ts
 *
 * @param queryEmbedding - Query embedding vector (1024 dimensions)
 * @param options - Search options including BM25 text search
 * @returns Array of search results
 */
export async function hybridGraphSearch(
  queryEmbedding: number[],
  options: {
    /** Original query text for BM25 search */
    query?: string;
    /** Enable BM25 text search (requires query) */
    useBM25?: boolean;
    similarityThreshold?: number;
    maxVectorResults?: number;
    maxGraphHops?: number;
    maxTotalResults?: number;
    /** Vector similarity weight (default: 0.5) */
    vectorWeight?: number;
    /** BM25 text search weight (default: 0.3) */
    textWeight?: number;
    /** Graph traversal weight (default: 0.2) */
    graphWeight?: number;
  } = {}
): Promise<LlamaIndexSearchResult[]> {
  await initializeLlamaIndex();

  const {
    query,
    useBM25 = false,
    similarityThreshold = 0.3,
    maxVectorResults = 5,
    maxGraphHops = 2,
    maxTotalResults = 15,
    vectorWeight = 0.5,
    textWeight = 0.3,
    graphWeight = 0.2,
  } = options;

  // Use BM25 hybrid search if enabled and query text is provided
  if (useBM25 && query) {
    console.log(`[LlamaIndex] Using BM25 hybrid search for: "${query.substring(0, 30)}..."`);

    try {
      const bm25Results = await hybridTextVectorSearch(query, queryEmbedding, {
        vectorWeight,
        textWeight,
        graphWeight,
        maxVectorResults,
        maxTextResults: maxVectorResults,
        maxTotalResults,
        threshold: similarityThreshold,
        maxGraphHops,
      });

      // Convert to LlamaIndexSearchResult format
      return bm25Results.map((r: TextSearchResult) => ({
        id: r.id,
        title: r.title,
        content: r.content,
        category: r.category,
        score: r.score,
        sourceType: r.sourceType === 'hybrid' ? 'vector' as const : 'graph' as const,
        hopDistance: r.hopDistance,
        metadata: {
          vectorScore: r.vectorScore,
          textScore: r.textScore,
          graphScore: r.graphScore,
        },
      }));
    } catch (error) {
      logger.warn('[LlamaIndex] BM25 search failed, falling back to vector-only:', error);
      // Fall through to vector-only search
    }
  }

  if (!supabaseClient) {
    logger.warn('‚ö†Ô∏è [LlamaIndex] Supabase not available');
    return [];
  }

  try {
    // 1. Direct vector search with embedding
    const { data: vectorData, error: vectorError } = await supabaseClient.rpc('match_documents', {
      query_embedding: queryEmbedding,
      match_count: maxVectorResults,
      filter: {},
    });

    if (vectorError) throw vectorError;

    const vectorResults: LlamaIndexSearchResult[] = (vectorData || []).map((row: Record<string, unknown>) => ({
      id: String(row.id),
      title: String(row.title || ''),
      content: String(row.content || ''),
      category: String(row.category || 'auto'),
      score: Number(row.similarity || 0),
      sourceType: 'vector' as const,
      hopDistance: 0,
      metadata: row.metadata as Record<string, unknown>,
    }));

    // 2. Graph traversal from vector results
    const graphResults = await traverseAndFetchGraphNodes(
      supabaseClient!, vectorResults, maxGraphHops
    );

    return mergeDeduplicateAndRankResults(vectorResults, graphResults, maxTotalResults);
  } catch (error) {
    logger.error('‚ùå [LlamaIndex] Hybrid graph search failed:', error);
    return [];
  }
}
export const getGraphRAGStats = getStats;

/**
 * Extract relationships from unprocessed knowledge base entries
 * Uses LlamaIndex triplet extraction with Mistral AI
 */
export const extractRelationships = async (options: {
  batchSize?: number;
  onlyUnprocessed?: boolean;
} = {}): Promise<ExtractionResult[]> => {
  await initializeLlamaIndex();

  const { batchSize = 50, onlyUnprocessed = true } = options;

  if (!supabaseClient) {
    logger.warn('‚ö†Ô∏è [LlamaIndex] Supabase not available');
    return [];
  }

  return extractRelationshipsFromKnowledgeBase(supabaseClient, extractTriplets, {
    batchSize,
    onlyUnprocessed,
  });
};

export const getRelatedKnowledge = async (
  nodeId: string,
  options: { maxHops?: number; maxResults?: number } = {}
) => {
  await initializeLlamaIndex();

  if (!supabaseClient) {
    return [];
  }

  return fetchRelatedKnowledgeFromGraph(supabaseClient, nodeId, options);
};
